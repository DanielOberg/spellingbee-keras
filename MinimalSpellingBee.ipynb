{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask==0.15.1 in /home/daniel/anaconda3/lib/python3.6/site-packages\n",
      "Collecting h5py==2.5.0\n",
      "  Using cached h5py-2.5.0.tar.gz\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/daniel/anaconda3/lib/python3.6/site-packages (from h5py==2.5.0)\n",
      "Requirement already satisfied: Cython>=0.17 in /home/daniel/anaconda3/lib/python3.6/site-packages (from h5py==2.5.0)\n",
      "Requirement already satisfied: six in /home/daniel/anaconda3/lib/python3.6/site-packages (from h5py==2.5.0)\n",
      "Building wheels for collected packages: h5py\n",
      "  Running setup.py bdist_wheel for h5py ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \berror\n",
      "  Complete output from command /home/daniel/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-sbt1_f2v/h5py/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/tmp6hv4j1ixpip-wheel- --python-tag cp36:\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.6\n",
      "  creating build/lib.linux-x86_64-3.6/h5py\n",
      "  copying h5py/highlevel.py -> build/lib.linux-x86_64-3.6/h5py\n",
      "  copying h5py/__init__.py -> build/lib.linux-x86_64-3.6/h5py\n",
      "  copying h5py/ipy_completer.py -> build/lib.linux-x86_64-3.6/h5py\n",
      "  copying h5py/version.py -> build/lib.linux-x86_64-3.6/h5py\n",
      "  creating build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/datatype.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/filters.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/selections.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/__init__.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/group.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/dataset.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/dims.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/attrs.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/selections2.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/files.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  copying h5py/_hl/base.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "  creating build/lib.linux-x86_64-3.6/h5py/tests\n",
      "  copying h5py/tests/__init__.py -> build/lib.linux-x86_64-3.6/h5py/tests\n",
      "  copying h5py/tests/common.py -> build/lib.linux-x86_64-3.6/h5py/tests\n",
      "  creating build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_group.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_attrs.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_selections.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_base.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/__init__.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_h5p.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_dimension_scales.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_datatype.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_slicing.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/common.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_h5t.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_h5f.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_file.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_dataset.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_h5.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_attrs_data.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  copying h5py/tests/old/test_objects.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "  creating build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "  copying h5py/tests/hl/__init__.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "  copying h5py/tests/hl/test_attribute_create.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "  copying h5py/tests/hl/test_dims_dimensionproxy.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "  copying h5py/tests/hl/test_dataset_getitem.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "  copying h5py/tests/hl/test_dataset_swmr.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "  copying h5py/tests/hl/test_file.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "  running build_ext\n",
      "  Autodetected HDF5 1.8.17\n",
      "  ********************************************************************************\n",
      "                         Summary of the h5py configuration\n",
      "  \n",
      "      Path to HDF5: None\n",
      "      HDF5 Version: '1.8.17'\n",
      "       MPI Enabled: False\n",
      "  Rebuild Required: False\n",
      "  \n",
      "  ********************************************************************************\n",
      "  Executing api_gen rebuild of defs\n",
      "  Executing cythonize()\n",
      "  ./h5py/api_types_ext.pxd: cannot find cimported module 'mpi4py.MPI'\n",
      "  /tmp/pip-build-sbt1_f2v/h5py/h5py/h5p.pyx: cannot find cimported module 'mpi4py.mpi_c'\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/defs.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/_errors.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/_objects.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/_proxy.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5fd.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5z.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5i.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5r.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/utils.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/_conv.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5t.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5s.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5p.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5d.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5a.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5f.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5g.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5l.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5o.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5ds.pyx because it changed.\n",
      "  Compiling /tmp/pip-build-sbt1_f2v/h5py/h5py/h5ac.pyx because it changed.\n",
      "  [ 1/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/_conv.pyx\n",
      "  [ 2/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/_errors.pyx\n",
      "  [ 3/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/_objects.pyx\n",
      "  [ 4/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/_proxy.pyx\n",
      "  [ 5/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/defs.pyx\n",
      "  [ 6/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5.pyx\n",
      "  [ 7/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5a.pyx\n",
      "  [ 8/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5ac.pyx\n",
      "  [ 9/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5d.pyx\n",
      "  [10/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5ds.pyx\n",
      "  [11/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5f.pyx\n",
      "  [12/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5fd.pyx\n",
      "  [13/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5g.pyx\n",
      "  [14/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5i.pyx\n",
      "  [15/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5l.pyx\n",
      "  [16/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5o.pyx\n",
      "  [17/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5p.pyx\n",
      "  [18/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5r.pyx\n",
      "  [19/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5s.pyx\n",
      "  [20/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5t.pyx\n",
      "  [21/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/h5z.pyx\n",
      "  [22/22] Cythonizing /tmp/pip-build-sbt1_f2v/h5py/h5py/utils.pyx\n",
      "  building 'h5py.defs' extension\n",
      "  creating build/temp.linux-x86_64-3.6\n",
      "  creating build/temp.linux-x86_64-3.6/tmp\n",
      "  creating build/temp.linux-x86_64-3.6/tmp/pip-build-sbt1_f2v\n",
      "  creating build/temp.linux-x86_64-3.6/tmp/pip-build-sbt1_f2v/h5py\n",
      "  creating build/temp.linux-x86_64-3.6/tmp/pip-build-sbt1_f2v/h5py/h5py\n",
      "  gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DH5_USE_16_API -I/tmp/pip-build-sbt1_f2v/h5py/lzf -I/opt/local/include -I/usr/local/include -I/home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/home/daniel/anaconda3/include/python3.6m -c /tmp/pip-build-sbt1_f2v/h5py/h5py/defs.c -o build/temp.linux-x86_64-3.6/tmp/pip-build-sbt1_f2v/h5py/h5py/defs.o\n",
      "  In file included from /home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1809:0,\n",
      "                   from /home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18,\n",
      "                   from /home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4,\n",
      "                   from /tmp/pip-build-sbt1_f2v/h5py/h5py/api_compat.h:26,\n",
      "                   from /tmp/pip-build-sbt1_f2v/h5py/h5py/defs.c:473:\n",
      "  /home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: #warning \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      "   #warning \"Using deprecated NumPy API, disable it by \" \\\n",
      "    ^\n",
      "  In file included from /tmp/pip-build-sbt1_f2v/h5py/h5py/defs.c:473:0:\n",
      "  /tmp/pip-build-sbt1_f2v/h5py/h5py/api_compat.h:27:18: fatal error: hdf5.h: No such file or directory\n",
      "  compilation terminated.\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for h5py\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for h5py\n",
      "Failed to build h5py\n",
      "Installing collected packages: h5py\n",
      "  Found existing installation: h5py 2.7.0\n",
      "    Uninstalling h5py-2.7.0:\n",
      "      Successfully uninstalled h5py-2.7.0\n",
      "  Running setup.py install for h5py ... \u001b[?25l-\b \b\\\b \b|\b \berror\n",
      "    Complete output from command /home/daniel/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-sbt1_f2v/h5py/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-queaji3c-record/install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/h5py\n",
      "    copying h5py/highlevel.py -> build/lib.linux-x86_64-3.6/h5py\n",
      "    copying h5py/__init__.py -> build/lib.linux-x86_64-3.6/h5py\n",
      "    copying h5py/ipy_completer.py -> build/lib.linux-x86_64-3.6/h5py\n",
      "    copying h5py/version.py -> build/lib.linux-x86_64-3.6/h5py\n",
      "    creating build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/datatype.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/filters.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/selections.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/__init__.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/group.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/dataset.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/dims.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/attrs.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/selections2.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/files.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    copying h5py/_hl/base.py -> build/lib.linux-x86_64-3.6/h5py/_hl\n",
      "    creating build/lib.linux-x86_64-3.6/h5py/tests\n",
      "    copying h5py/tests/__init__.py -> build/lib.linux-x86_64-3.6/h5py/tests\n",
      "    copying h5py/tests/common.py -> build/lib.linux-x86_64-3.6/h5py/tests\n",
      "    creating build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_group.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_attrs.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_selections.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_base.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/__init__.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_h5p.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_dimension_scales.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_datatype.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_slicing.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/common.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_h5t.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_h5f.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_file.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_dataset.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_h5.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_attrs_data.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    copying h5py/tests/old/test_objects.py -> build/lib.linux-x86_64-3.6/h5py/tests/old\n",
      "    creating build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "    copying h5py/tests/hl/__init__.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "    copying h5py/tests/hl/test_attribute_create.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "    copying h5py/tests/hl/test_dims_dimensionproxy.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "    copying h5py/tests/hl/test_dataset_getitem.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "    copying h5py/tests/hl/test_dataset_swmr.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "    copying h5py/tests/hl/test_file.py -> build/lib.linux-x86_64-3.6/h5py/tests/hl\n",
      "    running build_ext\n",
      "    Autodetected HDF5 1.8.17\n",
      "    ********************************************************************************\n",
      "                           Summary of the h5py configuration\n",
      "    \n",
      "        Path to HDF5: None\n",
      "        HDF5 Version: '1.8.17'\n",
      "         MPI Enabled: False\n",
      "    Rebuild Required: False\n",
      "    \n",
      "    ********************************************************************************\n",
      "    Executing cythonize()\n",
      "    ./h5py/api_types_ext.pxd: cannot find cimported module 'mpi4py.MPI'\n",
      "    /tmp/pip-build-sbt1_f2v/h5py/h5py/h5p.pyx: cannot find cimported module 'mpi4py.mpi_c'\n",
      "    building 'h5py.defs' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/tmp\n",
      "    creating build/temp.linux-x86_64-3.6/tmp/pip-build-sbt1_f2v\n",
      "    creating build/temp.linux-x86_64-3.6/tmp/pip-build-sbt1_f2v/h5py\n",
      "    creating build/temp.linux-x86_64-3.6/tmp/pip-build-sbt1_f2v/h5py/h5py\n",
      "    gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DH5_USE_16_API -I/tmp/pip-build-sbt1_f2v/h5py/lzf -I/opt/local/include -I/usr/local/include -I/home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/home/daniel/anaconda3/include/python3.6m -c /tmp/pip-build-sbt1_f2v/h5py/h5py/defs.c -o build/temp.linux-x86_64-3.6/tmp/pip-build-sbt1_f2v/h5py/h5py/defs.o\n",
      "    In file included from /home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1809:0,\n",
      "                     from /home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18,\n",
      "                     from /home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4,\n",
      "                     from /tmp/pip-build-sbt1_f2v/h5py/h5py/api_compat.h:26,\n",
      "                     from /tmp/pip-build-sbt1_f2v/h5py/h5py/defs.c:473:\n",
      "    /home/daniel/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: #warning \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      "     #warning \"Using deprecated NumPy API, disable it by \" \\\n",
      "      ^\n",
      "    In file included from /tmp/pip-build-sbt1_f2v/h5py/h5py/defs.c:473:0:\n",
      "    /tmp/pip-build-sbt1_f2v/h5py/h5py/api_compat.h:27:18: fatal error: hdf5.h: No such file or directory\n",
      "    compilation terminated.\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[?25h  Rolling back uninstall of h5py\n",
      "\u001b[31mCommand \"/home/daniel/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-sbt1_f2v/h5py/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-queaji3c-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-sbt1_f2v/h5py/\u001b[0m\n",
      "Collecting keras==2.0.4\n",
      "  Downloading Keras-2.0.4.tar.gz (199kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 3.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: theano in /home/daniel/anaconda3/lib/python3.6/site-packages (from keras==2.0.4)\n",
      "Requirement already satisfied: pyyaml in /home/daniel/anaconda3/lib/python3.6/site-packages (from keras==2.0.4)\n",
      "Requirement already satisfied: six in /home/daniel/anaconda3/lib/python3.6/site-packages (from keras==2.0.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/daniel/anaconda3/lib/python3.6/site-packages (from theano->keras==2.0.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/daniel/anaconda3/lib/python3.6/site-packages (from theano->keras==2.0.4)\n",
      "Building wheels for collected packages: keras\n",
      "  Running setup.py bdist_wheel for keras ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/daniel/.cache/pip/wheels/48/82/42/f06a8c03a8f95ada523a81ba723e89f059693e6ad868d09727\n",
      "Successfully built keras\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.0.6\n",
      "    Uninstalling Keras-2.0.6:\n",
      "      Successfully uninstalled Keras-2.0.6\n",
      "Successfully installed keras-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install dask==0.15.1\n",
    "!pip install h5py==2.5.0\n",
    "!pip install keras==2.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import os\n",
    "import librosa as lr\n",
    "import shutil\n",
    "import dask.array as da\n",
    "from dask.array.image import imread\n",
    "import h5py\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.misc import imresize\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, concatenate, add, GRU, LSTM ,Dense, Flatten, InputLayer, Dropout, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, Input, Conv1D, Reshape\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mp3_to_img(path, height=64, width=64):\n",
    "    signal, sr = lr.load(path, res_type='kaiser_fast')\n",
    "    hl = signal.shape[0]//(width) #this will cut away 5% from start and end\n",
    "    spec = lr.feature.melspectrogram(signal, n_mels=height, hop_length=int(hl))\n",
    "    img = lr.logamplitude(spec)**2\n",
    "    start = (img.shape[1] - width) // 2\n",
    "    return img[:, start:start+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gya     1288\n",
       "n        957\n",
       "ka       911\n",
       "o        895\n",
       "to       842\n",
       "shi      821\n",
       "ko       819\n",
       "i        815\n",
       "u        808\n",
       "hi       782\n",
       "ku       775\n",
       "no       769\n",
       "na       747\n",
       "mo       730\n",
       "mi       721\n",
       "ta       716\n",
       "ji       709\n",
       "ni       702\n",
       "ne       701\n",
       "ha       701\n",
       "go       700\n",
       "chi      697\n",
       "tsu      694\n",
       "a        694\n",
       "ma       694\n",
       "ki       693\n",
       "ru       693\n",
       "wa       693\n",
       "ge       690\n",
       "bi       689\n",
       "        ... \n",
       "hyu      644\n",
       "byu      644\n",
       "pu       644\n",
       "pyu      644\n",
       "ja       644\n",
       "wi       644\n",
       "pyo      644\n",
       "pya      644\n",
       "pe       644\n",
       "we       644\n",
       "ju       644\n",
       "mya      644\n",
       "pi       644\n",
       "po       644\n",
       "hyo      644\n",
       "myu      644\n",
       "dash     644\n",
       "hya      644\n",
       "nya      644\n",
       "wo       644\n",
       "rya      644\n",
       "myo      644\n",
       "chu      644\n",
       "nyo      644\n",
       "yo       644\n",
       "kyu      644\n",
       "pa       644\n",
       "bya      644\n",
       "kya      644\n",
       "gyo      644\n",
       "Name: Phonetics, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_list.csv').sample(frac=1).reset_index(drop=True)\n",
    "train.Phonetics.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_x = []\n",
    "temp_y = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    img_name = row['Filename']\n",
    "    img_path = os.path.join('data/jpg/', img_name + '.jpg')\n",
    "    img = imread(img_path) #mp3_to_img(os.path.join('data/raw/', img_name + '.wav'))\n",
    "    #img = imresize(img, (60, 12), interp='nearest')\n",
    "    img = img.reshape(36, 44, 1)\n",
    "    temp_x.append(img.astype('float32'))\n",
    "    \n",
    "train_x = np.stack(temp_x)\n",
    "\n",
    "train_x = train_x / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import dask.array as da\n",
    "\n",
    "da.from_array(train_x, chunks=1000).to_hdf5('data/data.h5', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = h5py.File('./data/data.h5', 'r')['data']\n",
    "train_x = da.from_array(train_x, chunks=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gya     1288\n",
       "n        957\n",
       "ka       911\n",
       "o        895\n",
       "to       842\n",
       "shi      821\n",
       "ko       819\n",
       "i        815\n",
       "u        808\n",
       "hi       782\n",
       "ku       775\n",
       "no       769\n",
       "na       747\n",
       "mo       730\n",
       "mi       721\n",
       "ta       716\n",
       "ji       709\n",
       "ni       702\n",
       "ne       701\n",
       "ha       701\n",
       "go       700\n",
       "chi      697\n",
       "tsu      694\n",
       "a        694\n",
       "ma       694\n",
       "ki       693\n",
       "ru       693\n",
       "wa       693\n",
       "ge       690\n",
       "bi       689\n",
       "        ... \n",
       "hyu      644\n",
       "byu      644\n",
       "pu       644\n",
       "pyu      644\n",
       "ja       644\n",
       "wi       644\n",
       "pyo      644\n",
       "pya      644\n",
       "pe       644\n",
       "we       644\n",
       "ju       644\n",
       "mya      644\n",
       "pi       644\n",
       "po       644\n",
       "hyo      644\n",
       "myu      644\n",
       "dash     644\n",
       "hya      644\n",
       "nya      644\n",
       "wo       644\n",
       "rya      644\n",
       "myo      644\n",
       "chu      644\n",
       "nyo      644\n",
       "yo       644\n",
       "kyu      644\n",
       "pa       644\n",
       "bya      644\n",
       "kya      644\n",
       "gyo      644\n",
       "Name: Phonetics, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Phonetics.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAAD8CAYAAAAmAyLtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl4hkScVLRLKk4iUiWfp/Yt5iSCurE38AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50d9033198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img = train_x[0, :, :, 0]\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'ba', 'be', 'bi', 'bo', 'bu', 'bya', 'byo', 'byu', 'cha', 'chi', 'cho', 'chu', 'da', 'dash', 'de', 'do', 'e', 'fu', 'ga', 'ge', 'gi', 'go', 'gu', 'gya', 'gyo', 'gyu', 'ha', 'he', 'hi', 'ho', 'hya', 'hyo', 'hyu', 'i', 'ja', 'ji', 'jo', 'ju', 'ka', 'ke', 'ki', 'ko', 'ku', 'kya', 'kyo', 'kyu', 'ma', 'me', 'mi', 'mo', 'mu', 'mya', 'myo', 'myu', 'n', 'na', 'ne', 'ni', 'no', 'nu', 'nya', 'nyo', 'nyu', 'o', 'pa', 'pe', 'pi', 'po', 'pu', 'pya', 'pyo', 'pyu', 'ra', 're', 'ri', 'ro', 'ru', 'rya', 'ryo', 'ryu', 'sa', 'se', 'sha', 'shi', 'sho', 'shu', 'so', 'su', 'ta', 'te', 'to', 'tsu', 'u', 'wa', 'we', 'wi', 'wo', 'xtsu', 'ya', 'yo', 'yu', 'za', 'ze', 'zo', 'zu']\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train.Phonetics)\n",
    "train_y = keras.utils.np_utils.to_categorical(train_y)\n",
    "print(list(lb.classes_))\n",
    "\n",
    "#with open('./data/classes.txt', 'wb') as fp:\n",
    "#    fp.write(\"\\n\".join(list(lb.classes_)).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72863\n",
      "36\n",
      "44\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape[0])\n",
    "print(train_x.shape[1])\n",
    "print(train_x.shape[2])\n",
    "print(train_x.shape[3])\n",
    "#train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2] * train_x.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_num_units = (36, 44, 1)\n",
    "hidden_num_units = 200\n",
    "output_num_units = len(train.Phonetics.value_counts())\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  InputLayer(input_shape=input_num_units),\n",
    "  Conv2D(64, kernel_size=(10, 44), activation='relu', padding='same'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Flatten(),\n",
    "  Dense(200, activation=\"relu\"),\n",
    "  Dropout(0.25),\n",
    "  Dense(200, activation=\"relu\"),\n",
    "  Dropout(0.25),\n",
    "  Dense(units=output_num_units, activation='softmax'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  InputLayer(input_shape=input_num_units),\n",
    "  Flatten(),\n",
    "  Dense(500, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "  Dense(500, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "  Dense(500, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "  Dropout(0.25),\n",
    "  Dense(500, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "  Dropout(0.25),\n",
    "  Dense(units=output_num_units, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn_size = 160\n",
    "\n",
    "input_tensor = Input(shape=input_num_units)\n",
    "x = input_tensor\n",
    "conv_shape = x.get_shape()\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=input_num_units),\n",
    "    Reshape(target_shape = (int(conv_shape [1]), int(conv_shape[2] * conv_shape[3]))),\n",
    "    LSTM(500, return_sequences=True),\n",
    "    LSTM(500, return_sequences=True),\n",
    "    LSTM(500),\n",
    "    Dense(500, activation=\"relu\"),\n",
    "    Dense(output_num_units, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 36, 44, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1584)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               792500    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 106)               53106     \n",
      "=================================================================\n",
      "Total params: 1,597,106\n",
      "Trainable params: 1,597,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy', 'top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58290 samples, validate on 14573 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.6/site-packages/dask/core.py:306: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  elif type_arg is type(key) and arg == key:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82s - loss: 2.8174 - categorical_accuracy: 0.2587 - top_k_categorical_accuracy: 0.6003 - val_loss: 1.9978 - val_categorical_accuracy: 0.4084 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 2/100\n",
      "79s - loss: 1.8529 - categorical_accuracy: 0.4466 - top_k_categorical_accuracy: 0.8259 - val_loss: 1.4597 - val_categorical_accuracy: 0.5395 - val_top_k_categorical_accuracy: 0.8895\n",
      "Epoch 3/100\n",
      "80s - loss: 1.4094 - categorical_accuracy: 0.5569 - top_k_categorical_accuracy: 0.8993 - val_loss: 1.1363 - val_categorical_accuracy: 0.6278 - val_top_k_categorical_accuracy: 0.9330\n",
      "Epoch 4/100\n",
      "79s - loss: 1.1415 - categorical_accuracy: 0.6346 - top_k_categorical_accuracy: 0.9317 - val_loss: 0.9399 - val_categorical_accuracy: 0.6909 - val_top_k_categorical_accuracy: 0.9511\n",
      "Epoch 5/100\n",
      "78s - loss: 0.9733 - categorical_accuracy: 0.6844 - top_k_categorical_accuracy: 0.9515 - val_loss: 0.8321 - val_categorical_accuracy: 0.7225 - val_top_k_categorical_accuracy: 0.9611\n",
      "Epoch 6/100\n",
      "80s - loss: 0.8604 - categorical_accuracy: 0.7184 - top_k_categorical_accuracy: 0.9595 - val_loss: 0.7886 - val_categorical_accuracy: 0.7372 - val_top_k_categorical_accuracy: 0.9590\n",
      "Epoch 7/100\n",
      "79s - loss: 0.7789 - categorical_accuracy: 0.7423 - top_k_categorical_accuracy: 0.9664 - val_loss: 0.7046 - val_categorical_accuracy: 0.7639 - val_top_k_categorical_accuracy: 0.9699\n",
      "Epoch 8/100\n",
      "80s - loss: 0.7210 - categorical_accuracy: 0.7614 - top_k_categorical_accuracy: 0.9698 - val_loss: 0.6735 - val_categorical_accuracy: 0.7715 - val_top_k_categorical_accuracy: 0.9698\n",
      "Epoch 9/100\n",
      "79s - loss: 0.6771 - categorical_accuracy: 0.7753 - top_k_categorical_accuracy: 0.9722 - val_loss: 0.6729 - val_categorical_accuracy: 0.7860 - val_top_k_categorical_accuracy: 0.9720\n",
      "Epoch 10/100\n",
      "79s - loss: 0.6398 - categorical_accuracy: 0.7896 - top_k_categorical_accuracy: 0.9742 - val_loss: 0.6477 - val_categorical_accuracy: 0.7763 - val_top_k_categorical_accuracy: 0.9708\n",
      "Epoch 11/100\n",
      "80s - loss: 0.6168 - categorical_accuracy: 0.7951 - top_k_categorical_accuracy: 0.9762 - val_loss: 0.6170 - val_categorical_accuracy: 0.7971 - val_top_k_categorical_accuracy: 0.9743\n",
      "Epoch 12/100\n",
      "80s - loss: 0.5927 - categorical_accuracy: 0.8035 - top_k_categorical_accuracy: 0.9774 - val_loss: 0.6073 - val_categorical_accuracy: 0.7961 - val_top_k_categorical_accuracy: 0.9747\n",
      "Epoch 13/100\n",
      "79s - loss: 0.5714 - categorical_accuracy: 0.8085 - top_k_categorical_accuracy: 0.9789 - val_loss: 0.6393 - val_categorical_accuracy: 0.7893 - val_top_k_categorical_accuracy: 0.9722\n",
      "Epoch 14/100\n",
      "79s - loss: 0.5534 - categorical_accuracy: 0.8157 - top_k_categorical_accuracy: 0.9801 - val_loss: 0.6202 - val_categorical_accuracy: 0.8000 - val_top_k_categorical_accuracy: 0.9735\n",
      "Epoch 15/100\n",
      "80s - loss: 0.5406 - categorical_accuracy: 0.8198 - top_k_categorical_accuracy: 0.9815 - val_loss: 0.5711 - val_categorical_accuracy: 0.8141 - val_top_k_categorical_accuracy: 0.9732\n",
      "Epoch 16/100\n",
      "79s - loss: 0.5224 - categorical_accuracy: 0.8240 - top_k_categorical_accuracy: 0.9823 - val_loss: 0.5735 - val_categorical_accuracy: 0.8108 - val_top_k_categorical_accuracy: 0.9749\n",
      "Epoch 17/100\n",
      "80s - loss: 0.5082 - categorical_accuracy: 0.8294 - top_k_categorical_accuracy: 0.9832 - val_loss: 0.5795 - val_categorical_accuracy: 0.8167 - val_top_k_categorical_accuracy: 0.9768\n",
      "Epoch 18/100\n",
      "80s - loss: 0.5003 - categorical_accuracy: 0.8318 - top_k_categorical_accuracy: 0.9839 - val_loss: 0.5908 - val_categorical_accuracy: 0.8124 - val_top_k_categorical_accuracy: 0.9744\n",
      "Epoch 19/100\n",
      "80s - loss: 0.4851 - categorical_accuracy: 0.8376 - top_k_categorical_accuracy: 0.9843 - val_loss: 0.6069 - val_categorical_accuracy: 0.8075 - val_top_k_categorical_accuracy: 0.9739\n",
      "Epoch 20/100\n",
      "79s - loss: 0.4803 - categorical_accuracy: 0.8398 - top_k_categorical_accuracy: 0.9853 - val_loss: 0.5469 - val_categorical_accuracy: 0.8165 - val_top_k_categorical_accuracy: 0.9750\n",
      "Epoch 21/100\n",
      "79s - loss: 0.4768 - categorical_accuracy: 0.8422 - top_k_categorical_accuracy: 0.9856 - val_loss: 0.5279 - val_categorical_accuracy: 0.8243 - val_top_k_categorical_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      "79s - loss: 0.4699 - categorical_accuracy: 0.8429 - top_k_categorical_accuracy: 0.9868 - val_loss: 0.5982 - val_categorical_accuracy: 0.8154 - val_top_k_categorical_accuracy: 0.9753\n",
      "Epoch 23/100\n",
      "79s - loss: 0.4525 - categorical_accuracy: 0.8481 - top_k_categorical_accuracy: 0.9869 - val_loss: 0.5601 - val_categorical_accuracy: 0.8236 - val_top_k_categorical_accuracy: 0.9770\n",
      "Epoch 24/100\n",
      "79s - loss: 0.4416 - categorical_accuracy: 0.8518 - top_k_categorical_accuracy: 0.9884 - val_loss: 0.5804 - val_categorical_accuracy: 0.8225 - val_top_k_categorical_accuracy: 0.9750\n",
      "Epoch 25/100\n",
      "80s - loss: 0.4268 - categorical_accuracy: 0.8567 - top_k_categorical_accuracy: 0.9882 - val_loss: 0.5582 - val_categorical_accuracy: 0.8173 - val_top_k_categorical_accuracy: 0.9757\n",
      "Epoch 26/100\n",
      "80s - loss: 0.4282 - categorical_accuracy: 0.8567 - top_k_categorical_accuracy: 0.9889 - val_loss: 0.5499 - val_categorical_accuracy: 0.8302 - val_top_k_categorical_accuracy: 0.9778\n",
      "Epoch 27/100\n",
      "79s - loss: 0.4357 - categorical_accuracy: 0.8546 - top_k_categorical_accuracy: 0.9888 - val_loss: 0.6167 - val_categorical_accuracy: 0.8161 - val_top_k_categorical_accuracy: 0.9721\n",
      "Epoch 28/100\n",
      "78s - loss: 0.4273 - categorical_accuracy: 0.8575 - top_k_categorical_accuracy: 0.9893 - val_loss: 0.5453 - val_categorical_accuracy: 0.8255 - val_top_k_categorical_accuracy: 0.9788\n",
      "Epoch 29/100\n",
      "79s - loss: 0.4211 - categorical_accuracy: 0.8598 - top_k_categorical_accuracy: 0.9899 - val_loss: 0.5475 - val_categorical_accuracy: 0.8315 - val_top_k_categorical_accuracy: 0.9780\n",
      "Epoch 30/100\n",
      "79s - loss: 0.4172 - categorical_accuracy: 0.8605 - top_k_categorical_accuracy: 0.9902 - val_loss: 0.6046 - val_categorical_accuracy: 0.8279 - val_top_k_categorical_accuracy: 0.9759\n",
      "Epoch 31/100\n",
      "80s - loss: 0.4114 - categorical_accuracy: 0.8644 - top_k_categorical_accuracy: 0.9903 - val_loss: 0.5679 - val_categorical_accuracy: 0.8287 - val_top_k_categorical_accuracy: 0.9770\n",
      "Epoch 32/100\n",
      "79s - loss: 0.4144 - categorical_accuracy: 0.8636 - top_k_categorical_accuracy: 0.9903 - val_loss: 0.6142 - val_categorical_accuracy: 0.8216 - val_top_k_categorical_accuracy: 0.9744\n",
      "Epoch 33/100\n",
      "79s - loss: 0.4322 - categorical_accuracy: 0.8595 - top_k_categorical_accuracy: 0.9896 - val_loss: 0.6386 - val_categorical_accuracy: 0.8245 - val_top_k_categorical_accuracy: 0.9754\n",
      "Epoch 34/100\n",
      "79s - loss: 0.3763 - categorical_accuracy: 0.8737 - top_k_categorical_accuracy: 0.9920 - val_loss: 0.5523 - val_categorical_accuracy: 0.8394 - val_top_k_categorical_accuracy: 0.9769\n",
      "Epoch 35/100\n",
      "79s - loss: 0.4017 - categorical_accuracy: 0.8673 - top_k_categorical_accuracy: 0.9912 - val_loss: 0.6436 - val_categorical_accuracy: 0.8269 - val_top_k_categorical_accuracy: 0.9759\n",
      "Epoch 36/100\n",
      "80s - loss: 0.4084 - categorical_accuracy: 0.8656 - top_k_categorical_accuracy: 0.9909 - val_loss: 0.6409 - val_categorical_accuracy: 0.8255 - val_top_k_categorical_accuracy: 0.9743\n",
      "Epoch 37/100\n",
      "80s - loss: 0.3781 - categorical_accuracy: 0.8722 - top_k_categorical_accuracy: 0.9919 - val_loss: 0.6189 - val_categorical_accuracy: 0.8354 - val_top_k_categorical_accuracy: 0.9761\n",
      "Epoch 38/100\n",
      "80s - loss: 0.3908 - categorical_accuracy: 0.8722 - top_k_categorical_accuracy: 0.9921 - val_loss: 0.6428 - val_categorical_accuracy: 0.8225 - val_top_k_categorical_accuracy: 0.9752\n",
      "Epoch 39/100\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3s - loss: 1.5130 - categorical_accuracy: 0.5245 - top_k_categorical_accuracy: 0.8839 - val_loss: 1.6408 - val_categorical_accuracy: 0.4889 - val_top_k_categorical_accuracy: 0.8637\n",
    "#3s - loss: 1.5106 - categorical_accuracy: 0.5317 - top_k_categorical_accuracy: 0.8774 - val_loss: 1.2672 - val_categorical_accuracy: 0.6153 - val_top_k_categorical_accuracy: 0.9146\n",
    "#44s - loss: 1.6152 - categorical_accuracy: 0.5103 - top_k_categorical_accuracy: 0.8668 - val_loss: 1.1829 - val_categorical_accuracy: 0.6399 - val_top_k_categorical_accuracy: 0.9308\n",
    "\n",
    "# conv dense 100 epochs. 58s - loss: 0.2110 - categorical_accuracy: 0.9126 - top_k_categorical_accuracy: 0.9976 - val_loss: 0.6212 - val_categorical_accuracy: 0.8263 - val_top_k_categorical_accuracy: 0.9758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('MinimalSpellingBee.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "datagen = ImageDataGenerator(width_shift_range=0.25)\n",
    "\n",
    "datagen.fit(train_x)\n",
    "model.fit_generator(datagen.flow(train_x, train_y, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_x) / batch_size, epochs=epochs, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('MinimalSpellingBee.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_prob = model.predict(train_x[0].reshape(1,36,44,1)) \n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "print(y_prob)\n",
    "print(y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
